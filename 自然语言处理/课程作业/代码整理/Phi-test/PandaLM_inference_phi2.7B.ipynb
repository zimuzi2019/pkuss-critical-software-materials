{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vllm import LLM, SamplingParams\n",
    "# import json\n",
    "\n",
    "# model = \"/home2/xjw/LLaMA-Factory/models/llama3_lora_sft\"\n",
    "# llm = LLM(model=model, tensor_parallel_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/xjw/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-06 08:44:54,170\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-06 08:44:55 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='/home2/xjw/LLaMA-Factory/models/Phi3_2.7B', speculative_config=None, tokenizer='/home2/xjw/LLaMA-Factory/models/Phi3_2.7B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=/home2/xjw/LLaMA-Factory/models/Phi3_2.7B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-06 08:44:55 selector.py:153] Cannot use FlashAttention-2 backend for head size 80.\n",
      "INFO 06-06 08:44:55 selector.py:51] Using XFormers backend.\n",
      "INFO 06-06 08:44:56 selector.py:153] Cannot use FlashAttention-2 backend for head size 80.\n",
      "INFO 06-06 08:44:56 selector.py:51] Using XFormers backend.\n",
      "INFO 06-06 08:44:59 model_runner.py:146] Loading model weights took 5.1933 GB\n",
      "INFO 06-06 08:44:59 gpu_executor.py:83] # GPU blocks: 13371, # CPU blocks: 819\n",
      "INFO 06-06 08:45:02 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-06 08:45:02 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-06 08:45:09 model_runner.py:924] Graph capturing finished in 7 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "mode_path = \"/home2/xjw/LLaMA-Factory/models/Phi3_2.7B\"\n",
    "# lora_path = \"/home2/xjw/LLaMA-Factory/saves/Phi-2-2.7B/lora/train_2024-06-04-19-54-58/checkpoint-120\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path, local_files_only=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(mode_path, local_files_only=True)\n",
    "# lora_model  = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "\n",
    "# llm = LLM(model=lora_model, tensor_parallel_size=1)\n",
    "llm = LLM(model=mode_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def build_prompt(instruction, input, resp1, resp2, result=None, explain=None, ref=None):\n",
    "    rsp = f\"### Response 1:\\n{resp1}\\n\\n### Response 2:\\n{resp2}\"\n",
    "\n",
    "    if input:\n",
    "        input_sequence = f\"Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n{rsp}\\n\\n### Evaluation:\\n\"\n",
    "    else:\n",
    "        input_sequence = f\"Below are two responses for a given task. The task is defined by the Instruction. Evaluate the responses and generate a reference answer for the task.\\n\\n### Instruction:\\n{instruction}\\n\\n{rsp}\\n\\n### Evaluation:\\n\"\n",
    "\n",
    "\n",
    "    output_sequence = f\"{result}\\n\\n### Reason: {explain}\\n\\n### Reference: {ref}\\n\"\n",
    "    \n",
    "    return input_sequence, output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandalm_test_set_path = \"/home2/xjw/PandaLM/data/testset-v1.json\"\n",
    "\n",
    "pandalm_test_set = []\n",
    "with open(pandalm_test_set_path, \"r\") as f:\n",
    "  pandalm_test_set = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandalm_test_set_prompt = []\n",
    "for i in range(len(pandalm_test_set)):\n",
    "  for j in range(3):\n",
    "    pandalm_test_set_prompt.append(\n",
    "      build_prompt(\n",
    "        instruction=pandalm_test_set[i]['instruction'],\n",
    "        input=pandalm_test_set[i]['input'] if 'input' in pandalm_test_set[i] else None,\n",
    "        resp1=pandalm_test_set[i]['response1'],\n",
    "        resp2=pandalm_test_set[i]['response2'],\n",
    "        result=pandalm_test_set[i]['annotator' + str(j+1)] ,\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<|im_start|>user\\n{input}<|im_end|>\\n<|im_start|>assistant\\n\"\"\"\n",
    "\n",
    "inputs = [ prompt_template.format(input = i[0]) for i in pandalm_test_set_prompt[ : : 3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "Make the article available in a second language by translating it into it.\n",
      "\n",
      "### Input:\n",
      "Dentistry, also known as dental medicine and oral medicine, is the branch of medicine focused on the teeth, gums, and mouth. It consists of the study, diagnosis, prevention, management, and treatment of diseases, disorders, and conditions of the mouth, most commonly focused on dentition (the development and arrangement of teeth) as well as the oral mucosa. Dentistry may also encompass other aspects of the craniofacial complex including the temporomandibular joint. The practitioner is called a dentist.\n",
      "Translate to French:\n",
      "\n",
      "### Response 1:\n",
      "La dentisterie, également connue sous le nom de médecine dentaire et de médecine orale, est la branche de la médecine qui s'occupe des dents, des gencives et de la cavité buccale. Elle comprend l'étude, le diagnostic, la prévention, le traitement et la prise en charge des maladies, des affections et des conditions de la cavité buccale, y compris les dents et les tissus mous. Le praticien est appelé dentiste.\n",
      "\n",
      "### Response 2:\n",
      "Dentistry, also known as dental medicine and oral medicine, is the branch of medicine focused on the teeth, gums, and mouth. It consists of the study, diagnosis, prevention, management, and treatment of diseases, disorders, and conditions of the mouth, most commonly focused on dentition (the development and arrangement of teeth) as well as the oral mucosa. Dentistry may also encompass other aspects of the craniofacial complex including the temporomandibular joint. The practitioner is called a dentist.\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "print(inputs[6])\n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 999/999 [00:46<00:00, 21.58it/s, Generation Speed: 2375.40 toks/s]\n"
     ]
    }
   ],
   "source": [
    "from vllm.lora.request import LoRARequest\n",
    "\n",
    "stop_tokens = [\"<|im_end|>\"]\n",
    "# sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=1024)\n",
    "sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=1024, stop=stop_tokens)\n",
    "\n",
    "completions = llm.generate(inputs, sampling_params=sampling_params)\n",
    "# completions = llm.generate(inputs, sampling_params=sampling_params)\n",
    "\n",
    "generated_responses = [output.outputs[0].text for output in completions]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"/home2/xjw/output/pandalm_test_phi2.7B_set_output.json\"\n",
    "with open(file_path, \"w\") as f:\n",
    "  json.dump(generated_responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"/home2/xjw/output/pandalm_test_phi2.7B_set_output.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "  generated_responses = json.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "The sentence you are given might be too wordy, complicated, or unclear. Rewrite the sentence and make your writing clearer by keeping it concise. Whenever possible, break complex sentences into multiple sentences and eliminate unnecessary words.\n",
      "\n",
      "### Input:\n",
      "If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\n",
      "\n",
      "### Response 1:\n",
      "If you have any questions about my rate, please let me know.\n",
      "\n",
      "### Response 2:\n",
      "If you have any questions, please let me know.\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "### Reason: Response 2 is better because it is more concise and clear.\n",
      "\n",
      "### Reference: If you have any questions, please let me know.\n",
      "\n",
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "The sentence you are given might be too wordy, complicated, or unclear. Rewrite the sentence and make your writing clearer by keeping it concise. Whenever possible, break complex sentences into multiple sentences and eliminate unnecessary words.\n",
      "\n",
      "### Input:\n",
      "If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\n",
      "\n",
      "### Response 1:\n",
      "If you have any questions about my rate, please let me know.\n",
      "\n",
      "### Response 2:\n",
      "If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "### Reason: Both responses are clear and concise, but Response 2 is more accurate as it includes the phrase \"if you find it necessary to increase or decrease the scope for this project\" which was not in the original sentence.\n",
      "\n",
      "### Reference: If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\n",
      "\n",
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "Come up with some search queries on google about coding stuff.\n",
      "\n",
      "### Response 1:\n",
      "1. What is coding? \n",
      "2. How to code? \n",
      "3. How to write code? \n",
      "4. How to debug code? \n",
      "5. How to debug code? \n",
      "6. How to debug code? \n",
      "7. How to debug code? \n",
      "8. How to debug code? \n",
      "9. How to debug code?\n",
      "\n",
      "### Response 2:\n",
      "1. \"how to code\"\n",
      "2. \"best coding language\"\n",
      "3. \"best coding tutorials\"\n",
      "4. \"best coding resources\"\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "1. Response 2\n",
      "\n",
      "### Reason: Response 2 provides more specific and relevant search queries that are likely to yield more useful and informative results.\n",
      "\n",
      "### Reference: 1. \"How to code in Python\" 2. \"Best coding languages for beginners\" 3. \"Top coding tutorials for beginners\" 4. \"Best coding resources for beginners\"\n",
      "\n",
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "Come up with some search queries on google about coding stuff.\n",
      "\n",
      "### Response 1:\n",
      "1. Coding tutorials\n",
      "2. Coding languages\n",
      "3. Coding languages for beginners\n",
      "4. Coding languages for beginners\n",
      "5. Coding languages for beginners\n",
      "6. Coding languages for beginners\n",
      "7. Coding languages for beginners\n",
      "8. Coding languages for beginners\n",
      "9. Coding languages for beginners\n",
      "10. Coding languages for beginners\n",
      "11. Coding languages for beginners\n",
      "12. Coding languages for beginners\n",
      "13. Coding languages for beginners\n",
      "\n",
      "### Response 2:\n",
      "1. \"how to code\"\n",
      "2. \"best coding language\"\n",
      "3. \"best coding tutorials\"\n",
      "4. \"best coding resources\"\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "The second response is better because it provides more specific and relevant search queries.\n",
      "\n",
      "### Reference: 1. \"how to code\" 2. \"best coding language\" 3. \"best coding tutorials\" 4. \"best coding resources\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(generated_responses))\n",
    "print(inputs[0])\n",
    "print(generated_responses[0])\n",
    "\n",
    "print(inputs[1])\n",
    "print(generated_responses[1])\n",
    "\n",
    "# print(inputs[2])\n",
    "# print(generated_responses[2])\n",
    "\n",
    "# print(inputs[3])\n",
    "# print(generated_responses[3])\n",
    "\n",
    "print(inputs[4])\n",
    "print(generated_responses[4])\n",
    "\n",
    "print(inputs[5])\n",
    "print(generated_responses[5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generated_responses[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n",
      "['1', '2', '0', '0', '0', '0', '0', '0', '2', '2', '1', '1', '1', '0', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '2', '2', '1', '2', '2', '2', '1', '2', '1', '0', '2', '2', '1', '2', '2', '1', '1', '1', '0', '2', '1', '1', '2', '0', '0', '0', '0', '2', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '2', '1', '0', '0', '0', '0', '2', '2', '2', '2', '2', '2', '1', '1', '2', '1', '2', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '0', '1', '1', '2', '2', '2', '2', '1', '0', '0', '2', '2', '0', '0', '2', '2', '2', '2', '2', '2', '2', '1', '1', '2', '1', '2', '2', '1', '1', '1', '0', '2', '0', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '2', '1', '1', '1', '2', '2', '2', '1', '1', '2', '2', '2', '2', '0', '0', '0', '0', '0', '2', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '2', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '0', '0', '0', '0', '0', '0', '1', '2', '1', '2', '2', '2', '1', '1', '2', '1', '2', '2', '1', '2', '2', '2', '0', '2', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '0', '0', '0', '2', '1', '0', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '1', '0', '2', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '0', '0', '1', '1', '1', '2', '1', '1', '2', '2', '2', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '0', '1', '1', '1', '2', '2', '2', '2', '0', '2', '2', '2', '1', '2', '1', '1', '1', '1', '2', '2', '1', '1', '2', '1', '0', '2', '1', '1', '1', '1', '2', '0', '0', '0', '0', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '2', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '0', '1', '1', '2', '2', '1', '1', '0', '1', '2', '1', '2', '2', '2', '1', '2', '2', '2', '2', '2', '2', '1', '2', '1', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '2', '2', '2', '1', '2', '2', '2', '1', '1', '1', '2', '2', '2', '2', '2', '2', '1', '2', '2', '2', '2', '1', '1', '2', '1', '1', '0', '1', '1', '1', '2', '2', '0', '0', '0', '1', '2', '2', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '2', '1', '1', '1', '2', '1', '2', '1', '1', '2', '1', '1', '2', '2', '1', '2', '2', '2', '2', '0', '0', '1', '0', '1', '2', '0', '2', '1', '1', '2', '1', '1', '2', '1', '1', '0', '1', '2', '1', '0', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '0', '2', '2', '1', '2', '2', '2', '1', '2', '2', '2', '2', '1', '1', '1', '2', '2', '2', '1', '0', '1', '2', '2', '2', '1', '2', '1', '1', '1', '1', '2', '2', '2', '2', '1', '1', '1', '2', '1', '1', '1', '2', '2', '1', '1', '2', '2', '1', '2', '1', '0', '2', '1', '2', '2', '0', '0', '1', '1', '1', '1', '2', '1', '0', '1', '1', '1', '0', '1', '2', '1', '2', '2', '2', '0', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '0', '1', '0', '1', '0', '2', '2', '2', '1', '2', '2', '1', '1', '1', '2', '2', '2', '2', '0', '2', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "# ans = [ res.split(\"\\n\\n\")[0] for res in generated_responses]\n",
    "\n",
    "ans = [ res.split(\"\\n\")[0] for res in generated_responses]\n",
    "\n",
    "newlist = []\n",
    "\n",
    "\n",
    "# for s in ans:\n",
    "#     if \"Tie\" in s or \"both\" in s:\n",
    "#         newlist.append(\"0\")\n",
    "#     elif \"1\" in s or \"first\" in s:\n",
    "#         newlist.append(\"1\")\n",
    "#     elif \"2\" in s or \"second\" in s:\n",
    "#         newlist.append(\"2\")\n",
    "\n",
    "\n",
    "\n",
    "for s in ans:\n",
    "    if \"Tie\" in s:\n",
    "        newlist.append(\"0\")\n",
    "    elif \"both\" in s and \"But\" not in s and \"but\" not in s:\n",
    "        newlist.append(\"0\")\n",
    "    elif \"Both\" in s and \"But\" not in s and \"but\" not in s:\n",
    "        newlist.append(\"0\")\n",
    "    elif \"1\" in s or \"first\" in s:\n",
    "        newlist.append(\"1\")\n",
    "    elif \"2\" in s or \"second\" in s:\n",
    "        newlist.append(\"2\")   \n",
    "    elif \"Both\" in s:\n",
    "        newlist.append(\"0\")\n",
    "    \n",
    "ans = newlist\n",
    "print(len(ans))\n",
    "print(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 27.46\n",
      "F1: 33.71\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "category_1 = 0\n",
    "pred_1 = 0\n",
    "category_1_correct = 0\n",
    "category_2 = 0\n",
    "pred_2 = 0\n",
    "category_2_correct = 0\n",
    "category_3 = 0\n",
    "pred_3 = 0\n",
    "category_3_correct = 0\n",
    "\n",
    "for j in range(len(ans)):\n",
    "  for i in range(3):\n",
    "    label = pandalm_test_set_prompt[j * 3 + i][1].split(\"\\n\\n\")[0]\n",
    "    if label == ans[j]:\n",
    "        correct += 1\n",
    "        if ans[j] == \"0\":\n",
    "          category_1_correct += 1\n",
    "        if ans[j] == \"1\":\n",
    "          category_2_correct += 1\n",
    "        if ans[j] == \"2\":\n",
    "          category_3_correct += 1\n",
    "    \n",
    "    if ans[j] == \"0\":\n",
    "      pred_1 += 1\n",
    "    if ans[j] == \"1\":\n",
    "      pred_2 += 1\n",
    "    if ans[j] == \"2\":\n",
    "      pred_3 += 1\n",
    "      \n",
    "    if label == \"0\":\n",
    "      category_1 += 1\n",
    "    if label == \"1\":\n",
    "      category_2 += 1\n",
    "    if label == \"2\":\n",
    "      category_3 += 1   \n",
    "\n",
    "print(f\"Accuracy: {correct/len(pandalm_test_set_prompt) * 100:.2f}\")\n",
    "\n",
    "def f1_score(p, r):\n",
    "  return 2 * p * r / (p + r)\n",
    "\n",
    "p1 = category_1_correct / pred_1\n",
    "r1 = category_1_correct / category_1\n",
    "p2 = category_2_correct / pred_2\n",
    "r2 = category_2_correct / category_2\n",
    "p3 = category_3_correct / pred_3\n",
    "r3 = category_3_correct / category_3\n",
    "\n",
    "print(f\"F1: {(f1_score(p1, r1) + f1_score(p2, r2) + f1_score(p3, r3) ) * 100 / 3 :.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

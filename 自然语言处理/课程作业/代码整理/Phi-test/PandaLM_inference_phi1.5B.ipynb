{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/xjw/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-05 17:59:29,312\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-05 17:59:29 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='/home2/xzhu/model/phi1.5', speculative_config=None, tokenizer='/home2/xzhu/model/phi1.5', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=/home2/xzhu/model/phi1.5)\n",
      "INFO 06-05 17:59:37 model_runner.py:146] Loading model weights took 2.6419 GB\n",
      "INFO 06-05 17:59:39 gpu_executor.py:83] # GPU blocks: 23154, # CPU blocks: 1365\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.83 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM, SamplingParams\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoRARequest\n\u001b[0;32m---> 11\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home2/xzhu/model/phi1.5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_lora\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/entrypoints/llm.py:144\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    124\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    125\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    126\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    143\u001b[0m )\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/engine/llm_engine.py:359\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context)\u001b[0m\n\u001b[1;32m    356\u001b[0m     executor_class \u001b[38;5;241m=\u001b[39m GPUExecutor\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/engine/llm_engine.py:235\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, vision_language_config, speculative_config, decoding_config, executor_class, log_stats, usage_context)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m executor_class(\n\u001b[1;32m    223\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[1;32m    224\u001b[0m     cache_config\u001b[38;5;241m=\u001b[39mcache_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m     load_config\u001b[38;5;241m=\u001b[39mload_config,\n\u001b[1;32m    232\u001b[0m )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39membedding_mode:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_kv_caches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# If usage stat is enabled, collect relevant info.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_usage_stats_enabled():\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/engine/llm_engine.py:325\u001b[0m, in \u001b[0;36mLLMEngine._initialize_kv_caches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config\u001b[38;5;241m.\u001b[39mnum_gpu_blocks \u001b[38;5;241m=\u001b[39m num_gpu_blocks\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config\u001b[38;5;241m.\u001b[39mnum_cpu_blocks \u001b[38;5;241m=\u001b[39m num_cpu_blocks\n\u001b[0;32m--> 325\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_gpu_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cpu_blocks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:86\u001b[0m, in \u001b[0;36mGPUExecutor.initialize_cache\u001b[0;34m(self, num_gpu_blocks, num_cpu_blocks)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# NOTE: This is logged in the executor because there can be >1 worker\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# with other executors. We could log in the engine level, but work\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# remains to abstract away the device for non-GPU configurations.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# GPU blocks: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, # CPU blocks: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, num_gpu_blocks,\n\u001b[1;32m     84\u001b[0m             num_cpu_blocks)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_gpu_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cpu_blocks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/worker/worker.py:194\u001b[0m, in \u001b[0;36mWorker.initialize_cache\u001b[0;34m(self, num_gpu_blocks, num_cpu_blocks)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config\u001b[38;5;241m.\u001b[39mnum_gpu_blocks \u001b[38;5;241m=\u001b[39m num_gpu_blocks\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config\u001b[38;5;241m.\u001b[39mnum_cpu_blocks \u001b[38;5;241m=\u001b[39m num_cpu_blocks\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_cache_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warm_up_model()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/worker/worker.py:199\u001b[0m, in \u001b[0;36mWorker._init_cache_engine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_cache_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config\u001b[38;5;241m.\u001b[39mnum_gpu_blocks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_engine \u001b[38;5;241m=\u001b[39m \u001b[43mCacheEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_engine\u001b[38;5;241m.\u001b[39mgpu_cache\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/worker/cache_engine.py:57\u001b[0m, in \u001b[0;36mCacheEngine.__init__\u001b[0;34m(self, cache_config, model_config, parallel_config)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_backend \u001b[38;5;241m=\u001b[39m get_attn_backend(\n\u001b[1;32m     47\u001b[0m     model_config\u001b[38;5;241m.\u001b[39mget_num_attention_heads(parallel_config),\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size,\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Initialize the cache.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_allocate_kv_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_gpu_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allocate_kv_cache(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_cpu_blocks, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/vllm/worker/cache_engine.py:75\u001b[0m, in \u001b[0;36mCacheEngine._allocate_kv_cache\u001b[0;34m(self, num_blocks, device)\u001b[0m\n\u001b[1;32m     69\u001b[0m kv_cache: List[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# null block in CpuGpuBlockAllocator requires at least that\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# block to be zeroed-out.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# We zero-out everything for simplicity.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     kv_cache\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 75\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkv_cache_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kv_cache\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.83 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# from vllm import LLM, SamplingParams\n",
    "# import json\n",
    "\n",
    "# model = \"/home2/xjw/LLaMA-Factory/models/llama3_lora_sft\"\n",
    "# llm = LLM(model=model, tensor_parallel_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/xjw/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-06 18:59:42,613\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-06 18:59:43 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='/home2/xjw/LLaMA-Factory/models/Phi_1.5B', speculative_config=None, tokenizer='/home2/xjw/LLaMA-Factory/models/Phi_1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=/home2/xjw/LLaMA-Factory/models/Phi_1.5B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-06 18:59:46 model_runner.py:146] Loading model weights took 2.6419 GB\n",
      "INFO 06-06 18:59:46 gpu_executor.py:83] # GPU blocks: 23163, # CPU blocks: 1365\n",
      "INFO 06-06 18:59:50 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-06 18:59:50 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-06 18:59:56 model_runner.py:924] Graph capturing finished in 6 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "mode_path = \"/home2/xjw/LLaMA-Factory/models/Phi_1.5B\"\n",
    "# lora_path = \"/home2/xjw/LLaMA-Factory/saves/Phi-1.5-1.3B/lora/train_2024-06-04-19-54-58/checkpoint-120\"\n",
    "\n",
    "# lora_path = \"/home2/xjw/LLaMA-Factory/saves/Phi-1.5-1.3B/lora/train_2024-06-04-19-54-58/checkpoint-60\"\n",
    "# lora_path = \"/home2/xjw/LLaMA-Factory/saves/Phi-1.5-1.3B/lora/train_2024-06-04-19-54-58/checkpoint-90\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path, local_files_only=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(mode_path, local_files_only=True)\n",
    "# lora_model  = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "llm = LLM(model=mode_path)\n",
    "\n",
    "# llm = LLM(model=lora_model, tensor_parallel_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里改了下，原来 \"if result: \" 的判断会出问题\n",
    "def build_prompt(instruction, input, resp1, resp2, result=None, explain=None, ref=None):\n",
    "    rsp = f\"### Response 1:\\n{resp1}\\n\\n### Response 2:\\n{resp2}\"\n",
    "\n",
    "    if input:\n",
    "        input_sequence = f\"Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n{rsp}\\n\\n### Evaluation:\\n\"\n",
    "    else:\n",
    "        input_sequence = f\"Below are two responses for a given task. The task is defined by the Instruction. Evaluate the responses and generate a reference answer for the task.\\n\\n### Instruction:\\n{instruction}\\n\\n{rsp}\\n\\n### Evaluation:\\n\"\n",
    "\n",
    "\n",
    "    output_sequence = f\"{result}\\n\\n### Reason: {explain}\\n\\n### Reference: {ref}\\n\"\n",
    "    \n",
    "    return input_sequence, output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandalm_test_set_path = \"/home2/xjw/PandaLM/data/testset-v1.json\"\n",
    "\n",
    "pandalm_test_set = []\n",
    "with open(pandalm_test_set_path, \"r\") as f:\n",
    "  pandalm_test_set = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandalm_test_set_prompt = []\n",
    "for i in range(len(pandalm_test_set)):\n",
    "  for j in range(3):\n",
    "    pandalm_test_set_prompt.append(\n",
    "      build_prompt(\n",
    "        instruction=pandalm_test_set[i]['instruction'],\n",
    "        input=pandalm_test_set[i]['input'] if 'input' in pandalm_test_set[i] else None,\n",
    "        resp1=pandalm_test_set[i]['response1'],\n",
    "        resp2=pandalm_test_set[i]['response2'],\n",
    "        result=pandalm_test_set[i]['annotator' + str(j+1)] ,\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<|im_start|>user\\n{input}<|im_end|>\\n<|im_start|>assistant\\n\"\"\"\n",
    "\n",
    "inputs = [ prompt_template.format(input = i[0]) for i in pandalm_test_set_prompt[ : : 3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "Make the article available in a second language by translating it into it.\n",
      "\n",
      "### Input:\n",
      "Dentistry, also known as dental medicine and oral medicine, is the branch of medicine focused on the teeth, gums, and mouth. It consists of the study, diagnosis, prevention, management, and treatment of diseases, disorders, and conditions of the mouth, most commonly focused on dentition (the development and arrangement of teeth) as well as the oral mucosa. Dentistry may also encompass other aspects of the craniofacial complex including the temporomandibular joint. The practitioner is called a dentist.\n",
      "Translate to French:\n",
      "\n",
      "### Response 1:\n",
      "La dentisterie, également connue sous le nom de médecine dentaire et de médecine orale, est la branche de la médecine qui s'occupe des dents, des gencives et de la cavité buccale. Elle comprend l'étude, le diagnostic, la prévention, le traitement et la prise en charge des maladies, des affections et des conditions de la cavité buccale, y compris les dents et les tissus mous. Le praticien est appelé dentiste.\n",
      "\n",
      "### Response 2:\n",
      "Dentistry, also known as dental medicine and oral medicine, is the branch of medicine focused on the teeth, gums, and mouth. It consists of the study, diagnosis, prevention, management, and treatment of diseases, disorders, and conditions of the mouth, most commonly focused on dentition (the development and arrangement of teeth) as well as the oral mucosa. Dentistry may also encompass other aspects of the craniofacial complex including the temporomandibular joint. The practitioner is called a dentist.\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "print(inputs[6])\n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 999/999 [07:33<00:00,  2.20it/s, Generation Speed: 2254.09 toks/s]\n"
     ]
    }
   ],
   "source": [
    "from vllm.lora.request import LoRARequest\n",
    "\n",
    "stop_tokens = [\"<|im_end|>\"]\n",
    "sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=1024)\n",
    "# sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=1024, stop=stop_tokens)\n",
    "\n",
    "completions = llm.generate(inputs, sampling_params=sampling_params)\n",
    "# completions = llm.generate(inputs, sampling_params=sampling_params)\n",
    "\n",
    "generated_responses = [output.outputs[0].text for output in completions]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = \"output/pandalm_test_phi1.5B_set_output.json\"\n",
    "\n",
    "with open(files, \"w\") as f:\n",
    "  json.dump(generated_responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = \"output/pandalm_test_phi1.5B_set_output.json\"\n",
    "\n",
    "import json\n",
    "with open(files, \"r\") as f:\n",
    "  generated_responses = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "The sentence you are given might be too wordy, complicated, or unclear. Rewrite the sentence and make your writing clearer by keeping it concise. Whenever possible, break complex sentences into multiple sentences and eliminate unnecessary words.\n",
      "\n",
      "### Input:\n",
      "If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\n",
      "\n",
      "### Response 1:\n",
      "If you have any questions about my rate, please let me know.\n",
      "\n",
      "### Response 2:\n",
      "If you have any questions, please let me know.\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Once upon a time, in a small town called Maplewood, there lived a young girl named Lily. Lily was a curious and intelligent girl who loved to learn about the world around her. She had a particular interest in social studies and was always eager to explore new topics.\n",
      "\n",
      "One day, Lily's teacher, Mrs. Johnson, announced that the class would be studying globes and their features and symbols. Lily's eyes lit up with excitement as she had always been fascinated by the Earth and its various elements. She couldn't wait to dive into this new topic.\n",
      "\n",
      "As the days went by, Lily and her classmates learned about the different continents, oceans, and countries that make up our planet. They also discovered the importance of symbols on globes, such as the equator and the prime meridian. Lily found it fascinating how these symbols represented different aspects of the Earth's geography.\n",
      "\n",
      "One afternoon, Lily's friend, Emily, came over to her house to study together. Emily was also interested in social studies and they often discussed various topics. As they sat at Lily's desk, surrounded by textbooks and globes, they began to talk about their favorite subjects.\n",
      "\n",
      "\"I really enjoy learning about different cultures and traditions,\" Lily said. \"It's amazing how diverse our world is.\"\n",
      "\n",
      "Emily nodded in agreement. \"Yes, it's so interesting to learn about the customs and beliefs of people from different parts of the world. It helps us understand and appreciate their way of life.\"\n",
      "\n",
      "Lily smiled and continued, \"You know, I think it's important to have a good understanding of social studies because it helps us become more informed global citizens. We can learn from the past and make better decisions for the future.\"\n",
      "\n",
      "Emily nodded again, impressed by Lily's insight. \"You're absolutely right, Lily. Social studies teaches us about history, geography, and even economics. It's a subject that helps us make sense of the world we live in.\"\n",
      "\n",
      "As they delved deeper into their studies, Lily and Emily realized that they had a lot in common. They both loved learning about different cultures, exploring new places, and understanding the world around them. They decided to form a study group with a few other classmates who shared their passion for social studies.\n",
      "\n",
      "The study group met every week, discussing various topics related to social studies. They would bring in their globes and point out different features and symbols, just like they had learned in class. They would also share interesting facts and stories they had discovered during their research.\n",
      "\n",
      "One day, as they were studying together, Lily's younger brother, Jake, walked into the room. He was fascinated by what he saw and wanted to join in on the fun. Lily and Emily welcomed him with open arms, eager to share their knowledge with him.\n",
      "\n",
      "\"Jake, did you know that the Earth is divided into hemispheres?\" Lily asked, pointing to the globe on the table.\n",
      "\n",
      "Jake shook his head, his eyes wide with curiosity. \"No, I didn't. How does that work?\"\n",
      "\n",
      "Lily explained, \"Well, the Earth is divided into two hemispheres, the Northern Hemisphere and the Southern Hemisphere. The equator is an imaginary line that runs around the middle of the Earth, dividing it into the Northern Hemisphere and the Southern Hemisphere.\"\n",
      "\n",
      "Jake listened intently, absorbing every word. He was fascinated by the idea of dividing the Earth into different parts.\n",
      "\n",
      "As the study group continued their discussions, Lily, Emily, and Jake realized that they were not only learning about social studies but also developing important skills. They were improving their critical thinking, problem-solving, and communication skills. They were also learning how to work together as a team and support each other's learning.\n",
      "\n",
      "One day, as they were preparing for a social studies quiz, Lily's mom called them for dinner. They quickly packed up their study materials and headed to the dining table.\n",
      "\n",
      "During dinner, Lily's mom asked her about her day at school. Lily excitedly shared everything she had learned about globes and their features and symbols. Her mom listened attentively, impressed by her daughter's enthusiasm for learning.\n",
      "\n",
      "After dinner, Lily and her family gathered in the living room. Lily's dad, who was a history enthusiast, started telling them about the ancient civilizations that had used globes to navigate the seas. He explained how these early globes were not as accurate as the ones we have today, but they were still valuable tools for explorers and sailors.\n",
      "\n",
      "Lily's dad then asked her if she knew about the different symbols on globes. Lily confidently answered, \"Yes, I do! Symbols like the equator and the prime meridian help us understand the Earth's geography and time zones.\"\n",
      "\n",
      "Her dad smiled proudly and said, \"That's right, Lily! You're becoming quite the expert in this subject.\"\n",
      "\n",
      "Lily beamed with pride, feeling a\n",
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "The sentence you are given might be too wordy, complicated, or unclear. Rewrite the sentence and make your writing clearer by keeping it concise. Whenever possible, break complex sentences into multiple sentences and eliminate unnecessary words.\n",
      "\n",
      "### Input:\n",
      "If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\n",
      "\n",
      "### Response 1:\n",
      "If you have any questions about my rate, please let me know.\n",
      "\n",
      "### Response 2:\n",
      "If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "# Python script for 1.1.9: How to use the Python debugger to step through code and identify errors\n",
      "\n",
      "# Introduction:\n",
      "# The Python debugger is a powerful tool that allows you to step through your code line by line, inspect variables, and identify errors.\n",
      "# It is especially useful when you are debugging complex programs or when you want to understand how your code works.\n",
      "\n",
      "# 1. How to use the Python debugger to step through code and identify errors?\n",
      "# The Python debugger is a built-in module that you can use to step through your code and identify errors.\n",
      "# To use the debugger, you need to import it into your Python script:\n",
      "\n",
      "import pdb\n",
      "\n",
      "# 2. How to set a breakpoint in your code?\n",
      "# A breakpoint is a point in your code where the debugger will stop execution and allow you to inspect the state of your program.\n",
      "# To set a breakpoint, you can use the 'pdb.set_trace()' function:\n",
      "\n",
      "def divide(x, y):\n",
      "    pdb.set_trace()\n",
      "    return x / y\n",
      "\n",
      "# 3. How to step through your code line by line?\n",
      "# When you set a breakpoint in your code, the debugger will stop execution at that point and allow you to step through your code line by line.\n",
      "# To step through your code, you can use the 'n' (next) command:\n",
      "\n",
      "def multiply(x, y):\n",
      "    pdb.set_trace()\n",
      "    return x * y\n",
      "\n",
      "# 4. How to inspect variables and their values?\n",
      "# The Python debugger allows you to inspect variables and their values at any point in your code.\n",
      "# To inspect a variable, you can use the 'p' (print) command:\n",
      "\n",
      "def add(x, y):\n",
      "    pdb.set_trace()\n",
      "    return x + y\n",
      "\n",
      "# 5. How to continue execution of your code after a breakpoint?\n",
      "# Once you have set a breakpoint in your code, you can continue execution of your code by pressing 'c' (continue) or 'q' (quit) in the debugger.\n",
      "# This will continue execution of your code until the next breakpoint is reached.\n",
      "\n",
      "# Python script for 1.1.10: How to use the Python debugger to handle exceptions and errors\n",
      "\n",
      "# Introduction:\n",
      "# When writing code, it is inevitable that errors and exceptions will occur. The Python debugger can help you handle these errors and exceptions in a more efficient and effective way.\n",
      "\n",
      "# 1. How to handle exceptions and errors in Python?\n",
      "# In Python, exceptions are raised when an error occurs during the execution of a program. These exceptions can be handled using the try-except block.\n",
      "\n",
      "# Example:\n",
      "try:\n",
      "    x = int(input(\"Enter a number: \"))\n",
      "    y = 10 / x\n",
      "except ZeroDivisionError:\n",
      "    print(\"Cannot divide by zero\")\n",
      "\n",
      "# Explanation:\n",
      "# In this example, we are trying to divide a number by zero, which is not allowed in mathematics. The ZeroDivisionError exception is raised when we try to divide by zero. We handle this exception using the try-except block.\n",
      "\n",
      "# 2. How to handle multiple exceptions in Python?\n",
      "# We can handle multiple exceptions in the same try-except block.\n",
      "\n",
      "# Example:\n",
      "try:\n",
      "    x = int(input(\"Enter a number: \"))\n",
      "    y = 10 / x\n",
      "except (ValueError, ZeroDivisionError):\n",
      "    print(\"Invalid input or division by zero\")\n",
      "\n",
      "# Explanation:\n",
      "# In this example, we are trying to divide a number by zero, which is not allowed in mathematics. We also handle the ValueError exception, which is raised when the input is not a valid integer.\n",
      "\n",
      "# 3. How to handle exceptions in a specific function?\n",
      "# We can handle exceptions in a specific function using the try-except block.\n",
      "\n",
      "# Example:\n",
      "def divide(x, y):\n",
      "    try:\n",
      "        result = x / y\n",
      "    except ZeroDivisionError:\n",
      "        print(\"Cannot divide by zero\")\n",
      "    else:\n",
      "        return result\n",
      "\n",
      "# Explanation:\n",
      "# In this example, we are trying to divide two numbers. If the second number is zero, a ZeroDivisionError exception is raised. We handle this exception using the try-except block. If no exception is raised, we return the result.\n",
      "\n",
      "# 4. How to handle exceptions in a specific class?\n",
      "# We can handle exceptions in a specific class using the __try__ and __except__ methods.\n",
      "\n",
      "# Example:\n",
      "class MyClass:\n",
      "    def __init__(self, x):\n",
      "        self.x = x\n",
      "\n",
      "    def divide(self,\n",
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "Come up with some search queries on google about coding stuff.\n",
      "\n",
      "### Response 1:\n",
      "1. What is coding? \n",
      "2. How to code? \n",
      "3. How to write code? \n",
      "4. How to debug code? \n",
      "5. How to debug code? \n",
      "6. How to debug code? \n",
      "7. How to debug code? \n",
      "8. How to debug code? \n",
      "9. How to debug code?\n",
      "\n",
      "### Response 2:\n",
      "1. \"how to code\"\n",
      "2. \"best coding language\"\n",
      "3. \"best coding tutorials\"\n",
      "4. \"best coding resources\"\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "### Reference:\n",
      "1. What is coding? \n",
      "2. How to code? \n",
      "3. How to write code? \n",
      "4. How to debug code? \n",
      "5. How to debug code? \n",
      "6. How to debug code? \n",
      "7. How to debug code? \n",
      "8. How to debug code? \n",
      "9. How to debug code?\n",
      "\n",
      "\n",
      "\n",
      "Once upon a time, in a small town called Maplewood, there lived a young girl named Lily. Lily was a curious and intelligent girl who loved to learn new things. She had a passion for language arts and was always eager to expand her vocabulary.\n",
      "\n",
      "One day, Lily's teacher, Mrs. Johnson, announced that the class would be learning about multiple-meaning words and idioms. Lily was excited about this topic because she knew it would help her understand the different meanings of words and how to use them in context.\n",
      "\n",
      "As the lesson began, Mrs. Johnson explained that multiple-meaning words are words that have more than one meaning. She gave examples such as \"bank,\" which can mean a financial institution or the side of a river. Lily found this concept fascinating and couldn't wait to explore more words with multiple meanings.\n",
      "\n",
      "To make the lesson more engaging, Mrs. Johnson decided to use a hands-on activity. She handed out a set of cards to each student, each containing a multiple-meaning word. The students were instructed to read the word on the card and come up with two different meanings for it.\n",
      "\n",
      "Lily eagerly picked up her card and read the word \"bank.\" She thought for a moment and then raised her hand to share her answer. \"The word 'bank' can mean a financial institution or the side of a river,\" she said confidently.\n",
      "\n",
      "Mrs. Johnson smiled and nodded. \"That's correct, Lily! You've understood the concept perfectly. Now, let's move on to idioms.\"\n",
      "\n",
      "Idioms are phrases that have a figurative meaning different from the literal meaning of the words. They often use words or phrases that are not commonly known. Mrs. Johnson explained that idioms can be tricky to understand because their meanings cannot be deduced from the individual words.\n",
      "\n",
      "To illustrate this, Mrs. Johnson told a story about a boy named Jack who loved to play basketball. One day, Jack's friend asked him, \"Why do you always shoot the ball into the hoop?\" Jack replied, \"Because I'm trying to make a basket.\"\n",
      "\n",
      "The friend looked puzzled and said, \"But you're not trying to make a basket, you're trying to make a hole in the net!\" Jack was confused and asked, \"What do you mean?\"\n",
      "\n",
      "The friend explained, \"When you shoot the ball, you're not trying to make a hole in the net. You're trying to make a basket. It's an idiom that means you're trying to score a point.\"\n",
      "\n",
      "Lily listened intently to the story and realized that idioms can be confusing because they don't always make sense based on the individual words. She made a mental note to pay attention to idioms in her daily life.\n",
      "\n",
      "As the lesson continued, Mrs. Johnson introduced the concept of context clues. She explained that context clues are the words or phrases surrounding an unfamiliar word that can help us understand its meaning.\n",
      "\n",
      "To demonstrate this, Mrs. Johnson gave the class a sentence with an unknown word. She asked the students to identify the meaning of the word based on the context.\n",
      "\n",
      "The sentence was, \"The detective carefully examined the crime scene for any clues.\"\n",
      "\n",
      "Lily thought for a moment and then raised her hand. \"The word 'examined' means to look closely at something,\" she said confidently.\n",
      "\n",
      "Mrs. Johnson smiled and nodded. \"That's correct, Lily! You've used the context clues to determine the meaning of the word. Great job!\"\n",
      "\n",
      "Lily felt proud of herself for understanding the concept of context clues. She realized that by paying attention to the words and phrases around an unfamiliar word, she could figure out its meaning.\n",
      "\n",
      "As the class came to an end, Lily felt a sense of accomplishment. She had learned so much about multiple-meaning words, idioms, and context clues. She knew that these skills would help her become a better communicator and understand the world around her.\n",
      "\n",
      "From that day forward, Lily continued to explore the world of language arts. She read books, wrote stories, and practiced using new words and phrases. She knew that by expanding her vocabulary, she could express herself more effectively and connect with others.\n",
      "\n",
      "Lily's journey in language arts was just beginning, and she couldn't wait to see where it would take her. She knew that with her newfound knowledge, she would be able to navigate the world of words with confidence and understanding.\n",
      "\n",
      "And so, Lily's love for language arts grew stronger with each passing\n",
      "<|im_start|>user\n",
      "Below are two responses for a given task. The task is defined by the Instruction. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "Come up with some search queries on google about coding stuff.\n",
      "\n",
      "### Response 1:\n",
      "1. Coding tutorials\n",
      "2. Coding languages\n",
      "3. Coding languages for beginners\n",
      "4. Coding languages for beginners\n",
      "5. Coding languages for beginners\n",
      "6. Coding languages for beginners\n",
      "7. Coding languages for beginners\n",
      "8. Coding languages for beginners\n",
      "9. Coding languages for beginners\n",
      "10. Coding languages for beginners\n",
      "11. Coding languages for beginners\n",
      "12. Coding languages for beginners\n",
      "13. Coding languages for beginners\n",
      "\n",
      "### Response 2:\n",
      "1. \"how to code\"\n",
      "2. \"best coding language\"\n",
      "3. \"best coding tutorials\"\n",
      "4. \"best coding resources\"\n",
      "\n",
      "### Evaluation:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Once upon a time, in a small town called Greenville, there lived a young girl named Lily. Lily was a curious and intelligent girl who loved learning about the world around her. She had a particular interest in science, especially life science and the fascinating world of plants and animals.\n",
      "\n",
      "One sunny day, Lily's teacher, Mrs. Johnson, announced that the class would be going on a field trip to the local botanical garden. Lily was thrilled! She had always dreamed of seeing different types of plants and learning about their unique characteristics.\n",
      "\n",
      "The day of the field trip arrived, and Lily and her classmates hopped onto the school bus. As they drove through the town, Lily couldn't help but notice the beautiful houses and gardens along the way. She wondered how plants and animals interacted with their environment and how they adapted to survive.\n",
      "\n",
      "Finally, they arrived at the botanical garden, a vast green oasis filled with colorful flowers, towering trees, and a variety of plants and animals. Mrs. Johnson led the class to a section dedicated to different types of flowers.\n",
      "\n",
      "Lily's eyes widened with excitement as she saw the vibrant petals and delicate fragrance of the flowers. She approached a gardener named Mr. Anderson and asked him about the different types of flowers. Mr. Anderson explained that flowers are the reproductive organs of plants and come in various shapes, sizes, and colors.\n",
      "\n",
      "Lily was fascinated by this information and wanted to learn more. She asked Mr. Anderson if he could show her how to take care of flowers. Mr. Anderson smiled and agreed. He took Lily to a small greenhouse where he showed her how to plant seeds and water the plants.\n",
      "\n",
      "As Lily carefully tended to the flowers, she noticed a small bird perched on a nearby branch. It was a beautiful blue jay, and Lily couldn't help but feel a sense of wonder and awe. She asked Mr. Anderson about the bird and its habitat.\n",
      "\n",
      "Mr. Anderson explained that birds are animals that have feathers, beaks, and lay eggs. They build nests to lay their eggs and raise their young. He also told Lily that birds play an important role in pollination, helping plants reproduce by carrying pollen from one flower to another.\n",
      "\n",
      "Lily was amazed by the interconnectedness of plants and animals. She realized that every living thing had a purpose and played a vital role in maintaining the balance of nature.\n",
      "\n",
      "After spending the day at the botanical garden, Lily returned to school with a newfound appreciation for the natural world. She couldn't wait to share her experiences with her family and friends.\n",
      "\n",
      "Back at home, Lily's parents noticed her excitement and asked her about her day. Lily eagerly told them about the different types of flowers, the bird she saw, and the importance of plants and animals in our lives.\n",
      "\n",
      "Her parents listened attentively and encouraged her curiosity. They explained that science was all about asking questions, making observations, and finding answers. They also told Lily that she could pursue a career in science, just like her parents did.\n",
      "\n",
      "Lily's eyes sparkled with excitement as she imagined herself as a scientist, exploring the wonders of the natural world. She knew that her love for science and her desire to learn more would guide her on a lifelong journey of discovery.\n",
      "\n",
      "And so, Lily continued to nurture her curiosity and passion for science. She knew that by understanding the world around her, she could make a difference and contribute to the betterment of society.\n",
      "\n",
      "Real-world usecases:\n",
      "\n",
      "1. Conversation: Lily and her friend Emma are walking in a park. They notice a squirrel gathering nuts and wonder why it does that. They start a conversation about the importance of storing food for the winter and how squirrels play a role in seed dispersal.\n",
      "\n",
      "2. Story: Lily's class is learning about different types of trees. They decide to go on a nature walk and observe the trees in their neighborhood. They take pictures and create a scrapbook of their findings, including the different types of trees they saw and their unique characteristics.\n",
      "\n",
      "3. Debate: Lily's class is divided into two groups for a debate on the topic of deforestation. One group argues that deforestation is necessary for economic development, while the other group argues that it is harmful to the environment. Each group presents their arguments, supported by facts and examples, and engages in a respectful debate.\n",
      "\n",
      "4. Exercise: Look around your backyard or a nearby park. Identify three different types of plants and describe their unique characteristics.\n",
      "\n",
      "5. Exercise: Draw a picture of a flower and label its different parts, such as the petals, stamen, and pistil.\n",
      "\n",
      "6. Exercise: Research and write a short paragraph about a specific animal and its habitat. Include information about its diet, behavior, and adaptations.\n",
      "\n",
      "7. Exercise: Create a poster showcasing the importance of plants and animals in our daily lives. Include pictures and captions to illustrate your\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "\n",
    "print(inputs[0])\n",
    "print(generated_responses[0])\n",
    "\n",
    "print(inputs[1])\n",
    "print(generated_responses[1])\n",
    "\n",
    "# print(inputs[2])\n",
    "# print(generated_responses[2])\n",
    "\n",
    "# print(inputs[3])\n",
    "# print(generated_responses[3])\n",
    "\n",
    "print(inputs[4])\n",
    "print(generated_responses[4])\n",
    "\n",
    "print(inputs[5])\n",
    "print(generated_responses[5])\n",
    "\n",
    "# # print(inputs[133])\n",
    "# for i in range(13):\n",
    "#     print(generated_responses[i])\n",
    "# print(generated_responses[:13])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_responses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ans = [ res.split(\"\\n\\n\")[0] for res in generated_responses]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m ans \u001b[38;5;241m=\u001b[39m [ res\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgenerated_responses\u001b[49m]\n\u001b[1;32m      5\u001b[0m newlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m ans:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generated_responses' is not defined"
     ]
    }
   ],
   "source": [
    "# ans = [ res.split(\"\\n\\n\")[0] for res in generated_responses]\n",
    "\n",
    "ans = [ res.split(\"\\n\")[0] for res in generated_responses]\n",
    "\n",
    "newlist = []\n",
    "\n",
    "\n",
    "for s in ans:\n",
    "    if \"Tie\" in s or \"both\" in s:\n",
    "        newlist.append(\"0\")\n",
    "    elif \"1\" in s or \"first\" in s:\n",
    "        newlist.append(\"1\")\n",
    "    elif \"2\" in s or \"second\" in s:\n",
    "        newlist.append(\"2\")\n",
    "    \n",
    "    \n",
    "ans = newlist\n",
    "print(len(ans))\n",
    "print(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(p, r):\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m p \u001b[38;5;241m*\u001b[39m r \u001b[38;5;241m/\u001b[39m (p \u001b[38;5;241m+\u001b[39m r)\n\u001b[0;32m---> 43\u001b[0m p1 \u001b[38;5;241m=\u001b[39m \u001b[43mcategory_1_correct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpred_1\u001b[49m\n\u001b[1;32m     44\u001b[0m r1 \u001b[38;5;241m=\u001b[39m category_1_correct \u001b[38;5;241m/\u001b[39m category_1\n\u001b[1;32m     45\u001b[0m p2 \u001b[38;5;241m=\u001b[39m category_2_correct \u001b[38;5;241m/\u001b[39m pred_2\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "category_1 = 0\n",
    "pred_1 = 0\n",
    "category_1_correct = 0\n",
    "category_2 = 0\n",
    "pred_2 = 0\n",
    "category_2_correct = 0\n",
    "category_3 = 0\n",
    "pred_3 = 0\n",
    "category_3_correct = 0\n",
    "\n",
    "for j in range(len(ans)):\n",
    "  for i in range(3):\n",
    "    label = pandalm_test_set_prompt[j * 3 + i][1].split(\"\\n\\n\")[0]\n",
    "    if label == ans[j]:\n",
    "        correct += 1\n",
    "        if ans[j] == \"0\":\n",
    "          category_1_correct += 1\n",
    "        if ans[j] == \"1\":\n",
    "          category_2_correct += 1\n",
    "        if ans[j] == \"2\":\n",
    "          category_3_correct += 1\n",
    "    \n",
    "    if ans[j] == \"0\":\n",
    "      pred_1 += 1\n",
    "    if ans[j] == \"1\":\n",
    "      pred_2 += 1\n",
    "    if ans[j] == \"2\":\n",
    "      pred_3 += 1\n",
    "      \n",
    "    if label == \"0\":\n",
    "      category_1 += 1\n",
    "    if label == \"1\":\n",
    "      category_2 += 1\n",
    "    if label == \"2\":\n",
    "      category_3 += 1   \n",
    "\n",
    "print(f\"Accuracy: {correct/len(pandalm_test_set_prompt) * 100:.2f}\")\n",
    "\n",
    "def f1_score(p, r):\n",
    "  return 2 * p * r / (p + r)\n",
    "\n",
    "p1 = category_1_correct / pred_1\n",
    "r1 = category_1_correct / category_1\n",
    "p2 = category_2_correct / pred_2\n",
    "r2 = category_2_correct / category_2\n",
    "p3 = category_3_correct / pred_3\n",
    "r3 = category_3_correct / category_3\n",
    "\n",
    "print(f\"F1: {(f1_score(p1, r1) + f1_score(p2, r2) + f1_score(p3, r3) ) * 100 / 3 :.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

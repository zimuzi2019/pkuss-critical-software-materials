环境配置：

实验中创建两个 conda 虚拟环境，一个用于 LLaMA-Factory LoRA 微调，一个用于推理和测评。前者按照 [LLaMA-Factory github repo 的 README.md 文档](https://github.com/hiyouga/LLaMA-Factory/blob/main/README.md)说明配置，后者主要参考 [vLLM docs 的 installation 部分](https://docs.vllm.ai/en/latest/getting_started/installation.html)，另外根据实际使用情况额外安装了少量其他 pip 包。



提交内容说明：

- ./test_llama3.ipynb：用于下载 Meta-Llama3-8B-Instruct 模型。

- ./auto-j 文件夹 clone 自 [auto-j github repo](https://github.com/GAIR-NLP/auto-j)，用于在 Auto-J tesetset 上给微调的 LIama3 模型做 evaluation，这里只上传了我们修改和新增的代码和配置文件，没有上传实验时自动生成的中间结果文件。
- ./LLMBar 文件夹 clone 自 [LLMBar github repo](https://github.com/princeton-nlp/LLMBar)，用于在 LLBar 上给微调的 LIama3 模型做 evaluation，这里这里只上传了我们修改和新增的代码和配置文件，以及 dataset 子目录下实验时自动生成的最终结果文件。
- ./prompt 文件夹下为实验报告 "基于 GLM-3-turbo 的不同prompt尝试" 部分的代码和最终结果 json 文件。
- ./saves 文件夹用于存放使用 LLaMA-Factory LoRA 微调 Llama3 过程中自动保存的日志文件和模型，考虑大小，我们只**上传了训练过程中的 log 日志文件和训练参数配置文件**。
- ./train_data 文件夹下用于处理和存放用于微调 LIama3 的指令数据，我们这里只上传了用于从 PanLM trainset 中采样的 sample.py 文件和合并各部分训练数据并将其转换为 LLaMA-Factory 输入格式的 transform_format.ipynb 文件。 
- MTBench_inference.ipynb：用于在 MT-Bench 上给微调的 LIama3 模型做 evaluation，并测试不同 prompt 对结果的影响。
- PandaLM_inference.ipynb：用于在 PandaLM testset 上给微调的 LIama3 模型做 evaluation。
- Phi-test 文件夹和 QWen 文件夹下为仿造 PandaLM_inference.ipynb 编写的几个 \.ipynb 文件，用于在 PandaLM testset 上给测试的几个 Phi 系列和 QWen 系列模型做 evalutation。



其他我们认为没有必要上传的项目文件：

- ./LLaMA-Factory 文件夹 clone 自 [LLaMA-Factory github repo](https://github.com/hiyouga/LLaMA-Factory)，过程中我们没有修改源码。只在 data 目录下存放用于微调模型的 final_train_data.json 数据文件，并在 dataset_info.json 配置文件中添加了相应项。在 models 文件夹下存放下载的 Phi 系列模型和 QWen 系列模型以及合并了 LoRA 模块权重的微调后 LIama3 模型。在 examples/merge\_lora 目录下存放 LIama3 等几个模型的对应 LoRA 微调配置文件，通过简单修改 llama3_lora_sft.yaml 配置文件的对应配置项得到。

- ./FastChat 文件夹 clone 自 [FastChat github repo](https://github.com/lm-sys/FastChat/tree/main)，我们只用其获取 MT-bench multi-turn evaluation 的问题。

- ./model 文件夹：存放下载的 Llama3模型。
- ./mt_bench_human_judgements：存放下载的 [MT-Bench multi-turn evalution](https://huggingface.co/datasets/lmsys/mt_bench_human_judgments) 的数据集。
- ./output 文件夹下：测试的几个 Phi 系列模型和 QWen 系列模型在不同训练 steps 下输入 PandaLM testset 问题输出的文本。
- ./pandLM 文件夹 clone 自 [PandaLM github repo](https://github.com/WeOpenML/PandaLM)，我们只用到其中的 PandaLM 测试集文件。
-  微调模型采用不同形式 prompt 做 MT-Bench multi-turn evaluation 的几个输出文本文件。

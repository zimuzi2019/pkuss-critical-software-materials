{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vllm import LLM, SamplingParams\n",
    "# import json\n",
    "\n",
    "# model = \"/home2/xjw/LLaMA-Factory/models/llama3_lora_sft\"\n",
    "# llm = LLM(model=model, tensor_parallel_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/xjw/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-06 18:35:58,601\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-06 18:36:00 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='/home2/xjw/LLaMA-Factory/models/Qwen1.5-1.8B-Chat', speculative_config=None, tokenizer='/home2/xjw/LLaMA-Factory/models/Qwen1.5-1.8B-Chat', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=/home2/xjw/LLaMA-Factory/models/Qwen1.5-1.8B-Chat)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-06 18:36:03 model_runner.py:146] Loading model weights took 3.4653 GB\n",
      "INFO 06-06 18:36:04 gpu_executor.py:83] # GPU blocks: 22509, # CPU blocks: 1365\n",
      "INFO 06-06 18:36:07 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-06 18:36:07 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-06 18:36:13 model_runner.py:924] Graph capturing finished in 6 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "mode_path = \"/home2/xjw/LLaMA-Factory/models/Qwen1.5-1.8B-Chat\"\n",
    "# lora_path = \"/home2/xjw/LLaMA-Factory/saves/Phi3-4B-4k-Chat/lora/train_2024-06-05-21-06-40/checkpoint-90\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path, local_files_only=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(mode_path, local_files_only=True)\n",
    "# lora_model  = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "\n",
    "# llm = LLM(model=lora_model, tensor_parallel_size=1)\n",
    "llm = LLM(model=mode_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(instruction, input, resp1, resp2, result=None, explain=None, ref=None):\n",
    "    rsp = f\"### Response 1:\\n{resp1}\\n\\n### Response 2:\\n{resp2}\"\n",
    "\n",
    "    if input:\n",
    "        input_sequence = f\"Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n{rsp}\\n\\n### Evaluation:\\n\"\n",
    "    else:\n",
    "        input_sequence = f\"Below are two responses for a given task. The task is defined by the Instruction. Evaluate the responses and generate a reference answer for the task.\\n\\n### Instruction:\\n{instruction}\\n\\n{rsp}\\n\\n### Evaluation:\\n\"\n",
    "\n",
    "\n",
    "    output_sequence = f\"{result}\\n\\n### Reason: {explain}\\n\\n### Reference: {ref}\\n\"\n",
    "    \n",
    "    return input_sequence, output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandalm_test_set_path = \"/home2/xjw/PandaLM/data/testset-v1.json\"\n",
    "\n",
    "pandalm_test_set = []\n",
    "with open(pandalm_test_set_path, \"r\") as f:\n",
    "  pandalm_test_set = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandalm_test_set_prompt = []\n",
    "for i in range(len(pandalm_test_set)):\n",
    "  for j in range(3):\n",
    "    pandalm_test_set_prompt.append(\n",
    "      build_prompt(\n",
    "        instruction=pandalm_test_set[i]['instruction'],\n",
    "        input=pandalm_test_set[i]['input'] if 'input' in pandalm_test_set[i] else None,\n",
    "        resp1=pandalm_test_set[i]['response1'],\n",
    "        resp2=pandalm_test_set[i]['response2'],\n",
    "        result=pandalm_test_set[i]['annotator' + str(j+1)] ,\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\"\"\n",
    "inputs = [ prompt_template.format(input = i[0]) for i in pandalm_test_set_prompt[ : : 3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Below are two responses for a given task. The task is defined by the Instruction with an Input that provides further context. Evaluate the responses and generate a reference answer for the task.\n",
      "\n",
      "### Instruction:\n",
      "Make the article available in a second language by translating it into it.\n",
      "\n",
      "### Input:\n",
      "Dentistry, also known as dental medicine and oral medicine, is the branch of medicine focused on the teeth, gums, and mouth. It consists of the study, diagnosis, prevention, management, and treatment of diseases, disorders, and conditions of the mouth, most commonly focused on dentition (the development and arrangement of teeth) as well as the oral mucosa. Dentistry may also encompass other aspects of the craniofacial complex including the temporomandibular joint. The practitioner is called a dentist.\n",
      "Translate to French:\n",
      "\n",
      "### Response 1:\n",
      "La dentisterie, également connue sous le nom de médecine dentaire et de médecine orale, est la branche de la médecine qui s'occupe des dents, des gencives et de la cavité buccale. Elle comprend l'étude, le diagnostic, la prévention, le traitement et la prise en charge des maladies, des affections et des conditions de la cavité buccale, y compris les dents et les tissus mous. Le praticien est appelé dentiste.\n",
      "\n",
      "### Response 2:\n",
      "Dentistry, also known as dental medicine and oral medicine, is the branch of medicine focused on the teeth, gums, and mouth. It consists of the study, diagnosis, prevention, management, and treatment of diseases, disorders, and conditions of the mouth, most commonly focused on dentition (the development and arrangement of teeth) as well as the oral mucosa. Dentistry may also encompass other aspects of the craniofacial complex including the temporomandibular joint. The practitioner is called a dentist.\n",
      "\n",
      "### Evaluation:\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "print(inputs[6])\n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 999/999 [00:35<00:00, 27.88it/s, Generation Speed: 3403.34 toks/s]\n"
     ]
    }
   ],
   "source": [
    "from vllm.lora.request import LoRARequest\n",
    "\n",
    "stop_tokens = [\"<|end_header_id|>\", \"<|eot_id|>\"]\n",
    "# sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=1024)\n",
    "sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=1024, stop=stop_tokens)\n",
    "\n",
    "completions = llm.generate(inputs, sampling_params=sampling_params)\n",
    "\n",
    "generated_responses = [output.outputs[0].text for output in completions]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"/home2/xjw/output/pandalm_test_Qwen1.5-1.8B-Chat_set_output.json\"\n",
    "with open(file_path, \"w\") as f:\n",
    "  json.dump(generated_responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"/home2/xjw/output/pandalm_test_Qwen1.5-1.8B-Chat_set_output.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "  generated_responses = json.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "### Reason: Response 1 is better because it is more concise and clear.\n",
      "\n",
      "### Reference: If you have any questions, please let me know.\n",
      "\n",
      "### Reason: Both responses are clear and concise, but Response 1 is more concise.\n",
      "\n",
      "### Reference: If you have any questions about my rate, please let me know.\n",
      "\n",
      "### Reason: Response 1 is better because it provides a variety of search queries related to coding.\n",
      "\n",
      "### Reference: 1. What is coding? 2. How to code? 3. How to write code? 4. How to debug code? 5. How to debug code? 6. How to debug code? 7. How to debug code? 8. How to debug code? 9. How to debug code?\n",
      "\n",
      "### Reason: Response 1 is better because it provides more diverse and relevant search queries.\n",
      "\n",
      "### Reference: 1. \"coding tutorials\" 2. \"coding languages\" 3. \"coding languages for beginners\" 4. \"coding languages for beginners\" 5. \"coding languages for beginners\" 6. \"coding languages for beginners\" 7. \"coding languages for beginners\" 8. \"coding languages for beginners\" 9. \"coding languages for beginners\" 10. \"coding languages for beginners\" 11. \"coding languages for beginners\" 12. \"coding languages for beginners\" 13. \"coding languages for beginners\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(generated_responses))\n",
    "# print(inputs[0])\n",
    "print(generated_responses[0])\n",
    "\n",
    "# print(inputs[1])\n",
    "print(generated_responses[1])\n",
    "\n",
    "# print(inputs[2])\n",
    "# print(generated_responses[2])\n",
    "\n",
    "# print(inputs[3])\n",
    "# print(generated_responses[3])\n",
    "\n",
    "# print(inputs[4])\n",
    "print(generated_responses[4])\n",
    "\n",
    "# print(inputs[5])\n",
    "print(generated_responses[5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generated_responses[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "['1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '2', '2', '2', '1', '1', '1', '1', '1', '2', '0', '0', '2', '2', '1', '2', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '0', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '2', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '0', '0', '1', '0', '2', '1', '1', '0', '0', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '2', '1', '2', '2', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '1', '1', '2', '1', '2', '1', '0', '1', '0', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '2', '2', '2', '2', '1', '1', '2', '2', '2', '1', '1', '2', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '2', '0', '0', '2', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '1', '1', '2', '1', '2', '2', '2', '2', '2', '0', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '2', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '2', '2', '1', '1', '1', '1', '2', '1', '2', '1', '0', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '1', '1', '2', '2', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '2', '1', '2', '1', '0', '1', '1', '1', '2', '1', '1', '2', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '2', '1', '2', '2', '1', '1', '2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '1', '2', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '2', '1', '2', '2', '2', '2', '1', '2', '2', '2', '2', '2', '1', '2', '2', '2', '1', '2', '1', '2', '1', '2', '1', '1', '2', '2', '2', '2', '2', '1', '2', '1', '2', '2', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '2', '2', '2', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '2', '1', '1']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ans = [ res.split(\"\\n\\n\")[0] for res in generated_responses]\n",
    "\n",
    "ans = [ res.split(\"\\n\")[0] for res in generated_responses]\n",
    "\n",
    "newlist = []\n",
    "\n",
    "\n",
    "# for s in ans:\n",
    "    \n",
    "#     if \"1\" in s or \"first\" in s:\n",
    "#         newlist.append(\"1\")\n",
    "#     elif \"2\" in s or \"second\" in s:\n",
    "#         newlist.append(\"2\")\n",
    "#     elif \"Tie\" in s or \"both\" in s:\n",
    "#         newlist.append(\"0\")   \n",
    "\n",
    "\n",
    "# for s in ans:\n",
    "#     if \"Tie\" in s:\n",
    "#         newlist.append(\"0\")\n",
    "#     elif \"1\" in s or \"first\" in s:\n",
    "#         newlist.append(\"1\")\n",
    "#     elif \"2\" in s or \"second\" in s:\n",
    "#         newlist.append(\"2\")\n",
    "#     elif \"both\" in s:\n",
    "#         newlist.append(\"0\")\n",
    "    \n",
    "for s in ans:\n",
    "    if \"Tie\" in s:\n",
    "        newlist.append(\"0\")\n",
    "    elif \"both\" in s and \"But\" not in s and \"but\" not in s:\n",
    "        newlist.append(\"0\")\n",
    "    elif \"Both\" in s and \"But\" not in s and \"but\" not in s:\n",
    "        newlist.append(\"0\")\n",
    "    elif \"1\" in s or \"first\" in s:\n",
    "        newlist.append(\"1\")\n",
    "    elif \"2\" in s or \"second\" in s:\n",
    "        newlist.append(\"2\")\n",
    "        \n",
    "# for s in ans:\n",
    "#     if \"Tie\" in s or \"both\" in s:\n",
    "#         newlist.append(\"0\")\n",
    "#     elif \"1\" in s or \"first\" in s:\n",
    "#         newlist.append(\"1\")\n",
    "#     elif \"2\" in s or \"second\" in s:\n",
    "#         newlist.append(\"2\")\n",
    "        \n",
    "ans = newlist\n",
    "print(len(ans))\n",
    "print(ans)\n",
    "print(\"0\" in ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.22\n",
      "F1: 40.16\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "category_1 = 0\n",
    "pred_1 = 0\n",
    "category_1_correct = 0\n",
    "category_2 = 0\n",
    "pred_2 = 0\n",
    "category_2_correct = 0\n",
    "category_3 = 0\n",
    "pred_3 = 0\n",
    "category_3_correct = 0\n",
    "\n",
    "for j in range(len(ans)):\n",
    "  for i in range(3):\n",
    "    label = pandalm_test_set_prompt[j * 3 + i][1].split(\"\\n\\n\")[0]\n",
    "    if label == ans[j]:\n",
    "        correct += 1\n",
    "        if ans[j] == \"0\":\n",
    "          category_1_correct += 1\n",
    "        if ans[j] == \"1\":\n",
    "          category_2_correct += 1\n",
    "        if ans[j] == \"2\":\n",
    "          category_3_correct += 1\n",
    "    \n",
    "    if ans[j] == \"0\":\n",
    "      pred_1 += 1\n",
    "    if ans[j] == \"1\":\n",
    "      pred_2 += 1\n",
    "    if ans[j] == \"2\":\n",
    "      pred_3 += 1\n",
    "      \n",
    "    if label == \"0\":\n",
    "      category_1 += 1\n",
    "    if label == \"1\":\n",
    "      category_2 += 1\n",
    "    if label == \"2\":\n",
    "      category_3 += 1   \n",
    "\n",
    "print(f\"Accuracy: {correct/len(pandalm_test_set_prompt) * 100:.2f}\")\n",
    "\n",
    "def f1_score(p, r):\n",
    "  return 2 * p * r / (p + r)\n",
    "\n",
    "p1 = category_1_correct / pred_1\n",
    "r1 = category_1_correct / category_1\n",
    "p2 = category_2_correct / pred_2\n",
    "r2 = category_2_correct / category_2\n",
    "p3 = category_3_correct / pred_3\n",
    "r3 = category_3_correct / category_3\n",
    "\n",
    "print(f\"F1: {(f1_score(p1, r1) + f1_score(p2, r2) + f1_score(p3, r3) ) * 100 / 3 :.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
